{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "zuRaB-oAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "shengpeng ji", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=zuRaB-oAAAAJ&citpid=8", "affiliation": "Senior Research Scientist in HunYuan", "interests": ["Speech", "LLM"], "email_domain": "@zju.edu.cn", "homepage": "http://novateurjsp.github.io/", "citedby": 925, "publications": {"zuRaB-oAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Wavtokenizer: an efficient acoustic discrete codec tokenizer for audio language modeling", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:LkGwnXOMwfcC", "num_citations": 124, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11096367345508634509,16177471095289081602", "cites_id": ["11096367345508634509", "16177471095289081602"]}, "zuRaB-oAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:0EnyYjriUFMC", "num_citations": 115, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5311787723872082481,16735322993503076322,18235593151373916504,6517017524836128956,13598293931052786139", "cites_id": ["5311787723872082481", "16735322993503076322", "18235593151373916504", "6517017524836128956", "13598293931052786139"]}, "zuRaB-oAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:WF5omc3nYNoC", "num_citations": 113, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7518588568983734053,2787238557889171864,7628731254388044901,6558666482371939911", "cites_id": ["7518588568983734053", "2787238557889171864", "7628731254388044901", "6558666482371939911"]}, "zuRaB-oAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mega-tts: Zero-shot text-to-speech at scale with intrinsic inductive bias", "pub_year": "2023"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:u-x6o8ySG0sC", "num_citations": 99, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15692405188854768212", "cites_id": ["15692405188854768212"]}, "zuRaB-oAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Textrolspeech: A text style control speech corpus with codec language text-to-speech models", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:_FxGoFyzp5QC", "num_citations": 75, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13046717496015607869", "cites_id": ["13046717496015607869"]}, "zuRaB-oAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Wavchat: A survey of spoken dialogue models", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:MXK_kJrjxJIC", "num_citations": 69, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10592581576644801292,2803125932755251588,9518536819359559637", "cites_id": ["10592581576644801292", "2803125932755251588", "9518536819359559637"]}, "zuRaB-oAAAAJ:-f6ydRqryjwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Megatts 3: Sparse alignment enhanced latent diffusion transformer for zero-shot speech synthesis", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:-f6ydRqryjwC", "num_citations": 33, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14050935485489651971,1890248841776294070,5575608582937276225,6508096615234957809", "cites_id": ["14050935485489651971", "1890248841776294070", "5575608582937276225", "6508096615234957809"]}, "zuRaB-oAAAAJ:4JMBOYKVnBMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Omnibind: Large-scale omni multimodal representation via binding spaces", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:4JMBOYKVnBMC", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15812878167712032072", "cites_id": ["15812878167712032072"]}, "zuRaB-oAAAAJ:YFjsv_pBGBYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Language-codec: bridging discrete codec representations and speech language models", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:YFjsv_pBGBYC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15333061713300156908,2839252587650168133", "cites_id": ["15333061713300156908", "2839252587650168133"]}, "zuRaB-oAAAAJ:hMod-77fHWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ControlSpeech: Towards simultaneous and independent zero-shot speaker cloning and zero-shot language style control", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:hMod-77fHWUC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=403976369840040732,14773282453358650363", "cites_id": ["403976369840040732", "14773282453358650363"]}, "zuRaB-oAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MobileSpeech: A Fast and High-Fidelity Framework for Mobile Zero-Shot Text-to-Speech", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:qjMakFHDy7sC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15185926768577512217", "cites_id": ["15185926768577512217"]}, "zuRaB-oAAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VoxDialogue: Can Spoken Dialogue Systems Understand Information Beyond Words?", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:L8Ckcad2t8MC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6165359200339987314", "cites_id": ["6165359200339987314"]}, "zuRaB-oAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Muvi: Video-to-music generation with semantic alignment and rhythmic synchronization", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:roLk4NBRz8UC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16580481280231624909", "cites_id": ["16580481280231624909"]}, "zuRaB-oAAAAJ:_Qo2XoVZTnwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing Multimodal Unified Representations for Cross Modal Generalization", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:_Qo2XoVZTnwC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5855652756488203104,9808437389179873666", "cites_id": ["5855652756488203104", "9808437389179873666"]}, "zuRaB-oAAAAJ:NMxIlDl6LWMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CART: A Generative Cross-Modal Retrieval Framework with Coarse-To-Fine Semantic Modeling", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:NMxIlDl6LWMC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17963865233010865082", "cites_id": ["17963865233010865082"]}, "zuRaB-oAAAAJ:R3hNpaxXUhUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SpatialCLIP: Learning 3D-aware Image Representations from Spatially Discriminative Language", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:R3hNpaxXUhUC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15113088726414049003", "cites_id": ["15113088726414049003"]}, "zuRaB-oAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Llava-mr: Large language-and-vision assistant for video moment retrieval", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:kNdYIx-mwKoC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9761189933575309456", "cites_id": ["9761189933575309456"]}, "zuRaB-oAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UniCodec: Unified Audio Codec with Single Domain-Adaptive Codebook", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:dhFuZR0502QC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17430334025101578800", "cites_id": ["17430334025101578800"]}, "zuRaB-oAAAAJ:Wp0gIr-vW9MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:Wp0gIr-vW9MC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6158515685735989233", "cites_id": ["6158515685735989233"]}, "zuRaB-oAAAAJ:M3ejUd6NZC8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing Expressive Voice Conversion with Discrete Pitch-Conditioned Flow Matching Model", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:M3ejUd6NZC8C", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13476468829880104679", "cites_id": ["13476468829880104679"]}, "zuRaB-oAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Synctalklip: Highly synchronized lip-readable speaker generation with multi-task learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:ufrVoPGSRksC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9517869040528200200", "cites_id": ["9517869040528200200"]}, "zuRaB-oAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Generating neural networks for diverse networking classification tasks via hardware-aware neural architecture search", "pub_year": "2023"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:9yKSN-GCB0IC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17470836784139465015", "cites_id": ["17470836784139465015"]}, "zuRaB-oAAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Speech watermarking with discrete intermediate representations", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:ZeXyd9-uunAC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14858638060087355065", "cites_id": ["14858638060087355065"]}, "zuRaB-oAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "InSerter: Speech Instruction Following with Unsupervised Interleaved Pre-training", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:7PzlFSSx8tAC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1525001266722317528", "cites_id": ["1525001266722317528"]}, "zuRaB-oAAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Omnichat: Enhancing spoken dialogue systems with scalable synthetic data for diverse scenarios", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:YOwf2qJgpHMC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7494014608082809312", "cites_id": ["7494014608082809312"]}, "zuRaB-oAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "OmniSep: Unified Omni-Modality Sound Separation with Query-Mixup", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:Se3iqnhoufwC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15654564753412480687", "cites_id": ["15654564753412480687"]}, "zuRaB-oAAAAJ:4TOpqqG69KYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VoxpopuliTTS: a large-scale multilingual TTS corpus for zero-shot speech generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:4TOpqqG69KYC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6178992905211935793", "cites_id": ["6178992905211935793"]}, "zuRaB-oAAAAJ:HDshCWvjkbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "IRBridge: Solving Image Restoration Bridge with Pre-trained Generative Diffusion Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:HDshCWvjkbEC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18124095864041414391", "cites_id": ["18124095864041414391"]}, "zuRaB-oAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AudioVSR: Enhancing Video Speech Recognition with Audio Data", "pub_year": "2024"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:UebtZRa9Y70C", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16556727474561197706", "cites_id": ["16556727474561197706"]}, "zuRaB-oAAAAJ:mB3voiENLucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "WavReward: Spoken Dialogue Models With Generalist Reward Evaluators", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:mB3voiENLucC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5287452982438759321", "cites_id": ["5287452982438759321"]}, "zuRaB-oAAAAJ:IWHjjKOFINEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Astrea: A MOE-based Visual Understanding Model with Progressive Alignment", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:IWHjjKOFINEC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13044815670601635917", "cites_id": ["13044815670601635917"]}, "zuRaB-oAAAAJ:bEWYMUwI8FkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GTA: Towards generative text-to-audio retrieval via multi-scale tokenizer", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:bEWYMUwI8FkC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10722664497888288039", "cites_id": ["10722664497888288039"]}, "zuRaB-oAAAAJ:RHpTSmoSYBkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "T2A-Feedback: Improving Basic Capabilities of Text-to-Audio Generation via Fine-grained AI Feedback", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:RHpTSmoSYBkC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12315614978914049800", "cites_id": ["12315614978914049800"]}, "zuRaB-oAAAAJ:j3f4tGmQtD8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Open-set cross modal generalization via multimodal unified representation", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:j3f4tGmQtD8C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7694367832450015040", "cites_id": ["7694367832450015040"]}, "zuRaB-oAAAAJ:TQgYirikUcIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rhythm Controllable and Efficient Zero-Shot Voice Conversion via Shortcut Flow Matching", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:TQgYirikUcIC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=140718334018721935", "cites_id": ["140718334018721935"]}, "zuRaB-oAAAAJ:blknAaTinKkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "InteractSpeech: A Speech Dialogue Interaction Corpus for Spoken Dialogue Model", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:blknAaTinKkC", "num_citations": 0}, "zuRaB-oAAAAJ:isC4tDSrTZIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Entropy-based Coarse and Compressed Semantic Speech Representation Learning", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:isC4tDSrTZIC", "num_citations": 0}, "zuRaB-oAAAAJ:iH-uZ7U-co4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TAP: Parameter-efficient Task-Aware Prompting for Adverse Weather Removal", "pub_year": "2025"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:iH-uZ7U-co4C", "num_citations": 0}, "zuRaB-oAAAAJ:JV2RwH3_ST0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AHa-Bench: Benchmarking Audio Hallucinations in Large Audio-Language Models"}, "filled": false, "author_pub_id": "zuRaB-oAAAAJ:JV2RwH3_ST0C", "num_citations": 0}}, "citedby5y": 925, "hindex": 14, "hindex5y": 14, "i10index": 18, "i10index5y": 18, "cites_per_year": {"2023": 10, "2024": 194, "2025": 716, "2026": 3}, "updated": "2026-01-03 08:28:49.116506"}